{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"10_Fine Tuning.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[">> 1. Fine Tuning\n","\n","전이 학습을 할때 우리는 Convolution Layer가 있는 특징을 추출하는 부분을 고정시키고 학습하였습니다. \n","\n","그러나, 이 방식으로 정확도가 어느 정도 수준에서 올라가지 않는다면, \n","Convolution Layer의 일부 층을 추가 학습을 해서\n","특징 추출하는 부분이 학습 데이터의 특징을 더 잘 인식할 수 있도록 만들 수 있습니다. \n","\n","\n"],"metadata":{"id":"o5VqSSrtzkX7"}},{"cell_type":"markdown","source":["이전 강의의 VGG 모델의 Convolution Layer 부분이 특징을 추출하는 모습을 살펴봅시다.\n","\n","우선 데이터와 모델을 불러오겠습니다. "],"metadata":{"id":"x2SxoUzGpDoW"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiPXvGFsFOjs","executionInfo":{"status":"ok","timestamp":1657434661791,"user_tz":-540,"elapsed":2216,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"e913864b-10bb-4687-b744-e742e9d32b86"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","data_dir = '/content/drive/MyDrive/Tensorflow AI/New Masks Dataset'\n","\n","img_height = 150\n","img_width = 150\n","\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir+'/Train',    \n","  image_size=(img_height, img_width))\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir+'/Validation',    \n","  image_size=(img_height, img_width))\n","\n","test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  data_dir+'/Test',    \n","  image_size=(img_height, img_width))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YO3y14z4EbHu","executionInfo":{"status":"ok","timestamp":1657434665361,"user_tz":-540,"elapsed":3573,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"4afdcd85-3034-45fa-b4e8-aded77618272"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 600 files belonging to 2 classes.\n","Found 306 files belonging to 2 classes.\n","Found 100 files belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":["Transfer Learning에서 활용한 VGG 모델을 불러와보겠습니다. \n","\n","include_top = False를 설정한 경우 이미지를 분류하는 Fully Connected Layer가 없습니다. "],"metadata":{"id":"keC9wLDFWwnt"}},{"cell_type":"code","source":["from tensorflow.keras.applications import VGG16\n","vgg_model = VGG16(weights = 'imagenet',include_top=False, input_shape=(150,150,3))\n","vgg_model.trainable = False"],"metadata":{"id":"rdsy8a5eXi7e","executionInfo":{"status":"ok","timestamp":1657434666698,"user_tz":-540,"elapsed":1347,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["vgg_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBDzeHkopiT7","executionInfo":{"status":"ok","timestamp":1657434666698,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"c7453816-d2ad-434d-9b16-60e9e80cf337"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["이 모델에 이미지를 넣어보고 output이 어떤 형태인지 살펴봅시다"],"metadata":{"id":"K6H_CRQypsga"}},{"cell_type":"code","source":["\n","for imgs, lbs in test_ds.take(1):\n","  pred = vgg_model.predict(imgs)"],"metadata":{"id":"_d_pm58DpsAY","executionInfo":{"status":"ok","timestamp":1657434673459,"user_tz":-540,"elapsed":6763,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWpkd-lQqN67","executionInfo":{"status":"ok","timestamp":1657434673460,"user_tz":-540,"elapsed":20,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"8de5015d-402a-4c9d-daa4-98096eb5ce1a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 4, 4, 512)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["vgg 출력은 이미지당 4 x 4 커널 512개가 나오게 됩니다. \n","\n","커널은 weight와 bias로 이루어져있습니다. "],"metadata":{"id":"OOy5CYkMq2w1"}},{"cell_type":"code","source":["pred[0,:,:,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z4SsFScrDRr","executionInfo":{"status":"ok","timestamp":1657434673460,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"fa4b3d6d-fc63-4b9a-99c7-889dec9a42bc"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["0번 이미지의 kernel 출력 일부를 시각화하여 살펴봅시다. \n","\n","kernel 마다 이미지의 다른 특징을 추출하여 다른 값을 가지고 있는 것을 알 수 있습니다. "],"metadata":{"id":"FaPvgh-7relx"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","for i in range(32):  \n","  ax = plt.subplot(4, 8, i + 1)\n","  plt.imshow(pred[0,:,:,i], cmap = 'gray')\n","  plt.axis(\"off\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":516},"id":"tk5rEJpwrc_K","executionInfo":{"status":"ok","timestamp":1657434675395,"user_tz":-540,"elapsed":1948,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"212c9072-c408-477a-f405-211dc206a683"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 32 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["사전 학습 모델이 학습한 데이터셋과 새로 학습 하는 데이터셋이 차이가 크다면 특징을 추출할 때 그것에 적합하도록 Covolution 부분을 수정해야 합니다. "],"metadata":{"id":"Ca2XB1kesa5c"}},{"cell_type":"markdown","source":[">> 2. Fine tuning으로 학습하기"],"metadata":{"id":"zsN43CWGsrZv"}},{"cell_type":"markdown","source":["Fine tuning을 하기 전에 우선 전이학습을 통해 높은 수준의 정확도를 나타낼 수 있도록 학습해 줍니다. \n","\n","그 후에 fine tuning을 통해 추가로 정확도를 높입니다. \n","\n","VGG 모델을 불러와서 Transfer Learning을 진행합니다. \n","(기존에 정확도가 높았기 때문에 epoch를 줄여서 진행해보겠습니다. )"],"metadata":{"id":"Rgx7gyubvGEK"}},{"cell_type":"code","source":["from tensorflow.keras.applications import VGG16\n","vgg_model = VGG16(weights = 'imagenet',include_top=False, input_shape=(150,150,3))"],"metadata":{"id":"gXE1jSKutXzG","executionInfo":{"status":"ok","timestamp":1657434676221,"user_tz":-540,"elapsed":833,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["vgg_model.trainable = False"],"metadata":{"id":"mbwOAO3jvqsJ","executionInfo":{"status":"ok","timestamp":1657434676221,"user_tz":-540,"elapsed":12,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import Sequential, Model, layers\n","transfer_model = Sequential()\n","\n","transfer_model.add(vgg_model)\n","\n","transfer_model.add(layers.Flatten())\n","transfer_model.add(layers.Dense(256,activation='relu'))\n","transfer_model.add(layers.Dropout(0.5))\n","transfer_model.add(layers.Dense(1,activation='sigmoid'))\n","\n","transfer_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTzXNsUOvs_2","executionInfo":{"status":"ok","timestamp":1657434676221,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"a8899d78-2f62-4d8f-e7f5-31471a4ec43a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2097408   \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 16,812,353\n","Trainable params: 2,097,665\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["기존에 전이학습의 정확도가 매우 높았기 때문에 여기서는\n","epoch를 줄여서 학습을 진행하겠습니다. "],"metadata":{"id":"JTdEQml8v4tF"}},{"cell_type":"code","source":["transfer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","history = transfer_model.fit(train_ds, epochs=5, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5DBBxepxv6qi","executionInfo":{"status":"ok","timestamp":1657434710553,"user_tz":-540,"elapsed":34337,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"8f52ae96-7f9f-40b6-88ba-95cfa0a1053e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","19/19 [==============================] - 10s 448ms/step - loss: 3.4146 - acc: 0.9017 - val_loss: 1.0929 - val_acc: 0.9739\n","Epoch 2/5\n","19/19 [==============================] - 6s 288ms/step - loss: 0.9228 - acc: 0.9833 - val_loss: 1.2729 - val_acc: 0.9510\n","Epoch 3/5\n","19/19 [==============================] - 6s 288ms/step - loss: 1.0461 - acc: 0.9700 - val_loss: 1.1024 - val_acc: 0.9771\n","Epoch 4/5\n","19/19 [==============================] - 6s 290ms/step - loss: 0.6915 - acc: 0.9867 - val_loss: 1.1756 - val_acc: 0.9739\n","Epoch 5/5\n","19/19 [==============================] - 6s 290ms/step - loss: 0.2090 - acc: 0.9917 - val_loss: 1.1199 - val_acc: 0.9706\n"]}]},{"cell_type":"markdown","source":["이렇게 학습한 후에 Convolution layer 일부를 학습 가능하도록 변경하고 추가학습을 진행합니다. \n","\n","이때는 학습률을 더 작게해서 학습이 천천히 진행되도록 합니다. "],"metadata":{"id":"sRGCQOnOxumE"}},{"cell_type":"markdown","source":["위쪽의 15번에서 18번까지의 층을 학습 가능하도록 변경합니다. \n"],"metadata":{"id":"pyCA1njRuAoS"}},{"cell_type":"markdown","source":["VGG는 19개의 층이 존재합니다. 이 중에서 15에서 18번째 층을 학습 가능하도록 변경하겠습니다. "],"metadata":{"id":"szmDZfqfk3C7"}},{"cell_type":"code","source":["# 기본 모델에 몇 개의 층이 있는지 확인 합니다.\n","print(\"Number of layers in the base model: \", len(vgg_model.layers))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hv3uPhFUtnwL","executionInfo":{"status":"ok","timestamp":1657434710554,"user_tz":-540,"elapsed":28,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"5fe96968-ecfe-49e0-a720-b37c15261f19"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of layers in the base model:  19\n"]}]},{"cell_type":"code","source":["vgg_model.trainable = True\n","fine_tune_at = 15\n","for layer in vgg_model.layers[:fine_tune_at]:\n","  layer.trainable =  False"],"metadata":{"id":"cLooeBWouHkc","executionInfo":{"status":"ok","timestamp":1657434710554,"user_tz":-540,"elapsed":12,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["vgg 모델이 학습가능한 파라미터가 생긴것을 확인할 수 있습니다"],"metadata":{"id":"MaxSaeoouTbt"}},{"cell_type":"code","source":["vgg_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4S5f1oxvuSgj","executionInfo":{"status":"ok","timestamp":1657434710554,"user_tz":-540,"elapsed":12,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"c8cc817c-2504-4f34-a724-2989fb527dd3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 7,079,424\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["이제 추가 학습을 진행합니다. \n","\n","이때 Optimizer의 학습률을 더 작게해서 더 천천히 학습이 이뤄지도록 하겠습니다. \n","adam의 기본 학습률은 0.001 이며, 이를 0.0001로 변경하여 진행하겠습니다 .\n"],"metadata":{"id":"TO1uc6BGuiKt"}},{"cell_type":"code","source":["transfer_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['acc'])\n","history = transfer_model.fit(train_ds, epochs=10, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2_RUkE_XcFh","executionInfo":{"status":"ok","timestamp":1657434872908,"user_tz":-540,"elapsed":77298,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"8d4987aa-7663-4a50-aa12-85d68ba2b745"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","19/19 [==============================] - 8s 315ms/step - loss: 2.4999e-10 - acc: 1.0000 - val_loss: 1.1192 - val_acc: 0.9706\n","Epoch 2/10\n","19/19 [==============================] - 6s 300ms/step - loss: 0.2067 - acc: 0.9967 - val_loss: 3.5901 - val_acc: 0.9608\n","Epoch 3/10\n","19/19 [==============================] - 6s 300ms/step - loss: 0.6088 - acc: 0.9767 - val_loss: 2.2889 - val_acc: 0.9608\n","Epoch 4/10\n","19/19 [==============================] - 7s 304ms/step - loss: 0.7012 - acc: 0.9733 - val_loss: 0.6715 - val_acc: 0.9542\n","Epoch 5/10\n","19/19 [==============================] - 7s 304ms/step - loss: 0.0271 - acc: 0.9950 - val_loss: 0.1789 - val_acc: 0.9771\n","Epoch 6/10\n","19/19 [==============================] - 6s 300ms/step - loss: 0.0675 - acc: 0.9883 - val_loss: 0.2339 - val_acc: 0.9804\n","Epoch 7/10\n","19/19 [==============================] - 6s 299ms/step - loss: 0.0320 - acc: 0.9983 - val_loss: 0.2260 - val_acc: 0.9837\n","Epoch 8/10\n","19/19 [==============================] - 6s 299ms/step - loss: 0.0373 - acc: 0.9917 - val_loss: 0.2130 - val_acc: 0.9869\n","Epoch 9/10\n","19/19 [==============================] - 6s 301ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3377 - val_acc: 0.9771\n","Epoch 10/10\n","19/19 [==============================] - 6s 299ms/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.9547 - val_acc: 0.9771\n"]}]},{"cell_type":"code","source":["# 테스트셋 정확도 평가\n","\n","test_loss , test_acc = transfer_model.evaluate(test_ds)\n","print('test acc :{} test loss:{}'.format(test_acc,test_loss))"],"metadata":{"id":"bJ0c5vGv0osh","executionInfo":{"status":"ok","timestamp":1657434974410,"user_tz":-540,"elapsed":2593,"user":{"displayName":"Jooho Shin","userId":"16439599331136410701"}},"outputId":"812b5396-6150-4cc9-afeb-c03eb9e3d53c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 2s 308ms/step - loss: 0.0446 - acc: 0.9900\n","test acc :0.9900000095367432 test loss:0.04455021396279335\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"K7GR2K6g0pjS"},"execution_count":null,"outputs":[]}]}